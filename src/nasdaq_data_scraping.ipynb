{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WDB - Web scraping with selenium\n",
    "\n",
    "Rami Tarabishi - @r9119\n",
    "\n",
    "This notebook covers my attempt at webscraping company finiancials from [nasdaq.com](https://www.nasdaq.com/market-activity/stocks/screener)\n",
    "\n",
    "I did make use of chatGPT and Googles Bard when I had errors and will mention my troubles under each cell where they were, but honestly most of the time the solutions didnt help and I just figured it out on my own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "import pandas as pd\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_name</th>\n",
       "      <th>ticker_symbol</th>\n",
       "      <th>market_cap</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [company_name, ticker_symbol, market_cap, url]\n",
       "Index: []"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=['company_name', 'ticker_symbol', 'market_cap', 'url'])\n",
    "# Init dataframe with the columns I want that are located in the main table\n",
    "# I am first only scraping the table with the ticker symbols as the financial data is located in link/ticker_symbol\n",
    "# to later iterate over the list of symbols and scrape the financial data seperately \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "\n",
    "driver.get(\"https://www.nasdaq.com/market-activity/stocks/screener\")\n",
    "wait = WebDriverWait(driver, timeout=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close cookie consent banner as it blocks the pagination buttons\n",
    "cookie_consent_exit_button = driver.find_element(By.XPATH, '//*[@id=\"onetrust-close-btn-container\"]/button')\n",
    "cookie_consent_exit_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_table_page(table_page):\n",
    "    '''\n",
    "    Function to parse and extract data from a table page\n",
    "    -----\n",
    "    Input:\n",
    "        table_page: The page to be scraped\n",
    "    -----\n",
    "    Returns:\n",
    "        df: A dataframe containing the extracted data from that page\n",
    "    '''\n",
    "\n",
    "    try:\n",
    "        rows = table_page.find_elements(by=By.CLASS_NAME, value=\"nasdaq-screener__row\")\n",
    "    except:\n",
    "        print(\"Error: No rows found\")\n",
    "        return None\n",
    "    \n",
    "    data_list = []\n",
    "    for row in rows[1:]:\n",
    "        try:\n",
    "            ticker_symbol = row.find_element(by=By.CLASS_NAME, value=\"nasdaq-screener__cell\")\n",
    "            name = row.find_element(by=By.CLASS_NAME, value=\"nasdaq-screener__cell--name\").text\n",
    "            mc = row.find_element(by=By.CLASS_NAME, value=\"nasdaq-screener__cell--marketCap\").text\n",
    "\n",
    "            data_dict = {'company_name': name, 'ticker_symbol': ticker_symbol.text, 'market_cap': mc, 'url': ticker_symbol.find_element(by=By.TAG_NAME, value=\"a\").get_attribute('href')}\n",
    "            data_list.append(data_dict)\n",
    "        except TimeoutException:\n",
    "            print(\"Error: Couldnt extract data from row\")\n",
    "            continue\n",
    "    \n",
    "    return pd.DataFrame.from_dict(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First page of table\n",
    "stock_table = driver.find_element(by=By.CLASS_NAME, value=\"nasdaq-screener__table\")\n",
    "data_list = scrape_table_page(stock_table)\n",
    "df = pd.concat([df, data_list], ignore_index=True)\n",
    "\n",
    "# # Iterate over pages\n",
    "while True:\n",
    "    try:\n",
    "        next_page_button = driver.find_element(by=By.CLASS_NAME, value=\"pagination__next\")\n",
    "    except TimeoutException:\n",
    "        raise Exception(\"Error: Couldnt find next page button\")\n",
    "    \n",
    "    if next_page_button.get_attribute(\"disabled\") == \"true\":\n",
    "        print(\"Reached last page\")\n",
    "        break\n",
    "    else:\n",
    "        try:\n",
    "            # Force scroll to button and click (Button could be hidden by a banner)\n",
    "            driver.execute_script(f'window.scroll(0, {next_page_button.location[\"y\"]});')\n",
    "            next_page_button.click()\n",
    "            try:\n",
    "                # Wait for the new table to load\n",
    "                # time.sleep(5) # Dynamic waiting wasnt working so here we are (I figured it out â†“)\n",
    "                div_location = (By.CSS_SELECTOR, \".nasdaq-screener__data.loaded\")\n",
    "                wait.until(EC.visibility_of_element_located(div_location))\n",
    "\n",
    "                # Extract new table page\n",
    "                stock_table = driver.find_element(by=By.CLASS_NAME, value=\"nasdaq-screener__table\")\n",
    "\n",
    "                # Parse and extract data from new table page\n",
    "                data_list = scrape_table_page(stock_table)\n",
    "                df = pd.concat([df, data_list], ignore_index=True)\n",
    "            except TimeoutException:\n",
    "                raise Exception(\"Error: Couldnt find new table page\")\n",
    "        except TimeoutException:\n",
    "            raise Exception(\"Error: Couldnt click next page button\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like the comments say, I had some issues with the waiting between page loads, neither gpt3.5, 4 or bard helped much so I just used a time.sleep() function at first, and after reading more of the docs and more help from bard I eventually understood how to properly use the wait functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_name</th>\n",
       "      <th>ticker_symbol</th>\n",
       "      <th>market_cap</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apple Inc. Common Stock</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>3,028,976,215,760</td>\n",
       "      <td>https://www.nasdaq.com/market-activity/stocks/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Microsoft Corporation Common Stock</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>2,769,810,931,198</td>\n",
       "      <td>https://www.nasdaq.com/market-activity/stocks/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alphabet Inc. Class C Capital Stock</td>\n",
       "      <td>GOOG</td>\n",
       "      <td>1,725,330,600,000</td>\n",
       "      <td>https://www.nasdaq.com/market-activity/stocks/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alphabet Inc. Class A Common Stock</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>1,705,242,420,000</td>\n",
       "      <td>https://www.nasdaq.com/market-activity/stocks/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amazon.com, Inc. Common Stock</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>1,516,576,859,067</td>\n",
       "      <td>https://www.nasdaq.com/market-activity/stocks/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>CVS Health Corporation Common Stock</td>\n",
       "      <td>CVS</td>\n",
       "      <td>96,041,091,915</td>\n",
       "      <td>https://www.nasdaq.com/market-activity/stocks/cvs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>Marsh &amp; McLennan Companies, Inc. Common Stock</td>\n",
       "      <td>MMC</td>\n",
       "      <td>96,033,253,582</td>\n",
       "      <td>https://www.nasdaq.com/market-activity/stocks/mmc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>Automatic Data Processing, Inc. Common Stock</td>\n",
       "      <td>ADP</td>\n",
       "      <td>95,015,517,690</td>\n",
       "      <td>https://www.nasdaq.com/market-activity/stocks/adp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>Citigroup, Inc. Common Stock</td>\n",
       "      <td>C</td>\n",
       "      <td>93,956,674,631</td>\n",
       "      <td>https://www.nasdaq.com/market-activity/stocks/c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>Progressive Corporation (The) Common Stock</td>\n",
       "      <td>PGR</td>\n",
       "      <td>93,577,293,075</td>\n",
       "      <td>https://www.nasdaq.com/market-activity/stocks/pgr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      company_name ticker_symbol  \\\n",
       "0                          Apple Inc. Common Stock          AAPL   \n",
       "1               Microsoft Corporation Common Stock          MSFT   \n",
       "2              Alphabet Inc. Class C Capital Stock          GOOG   \n",
       "3               Alphabet Inc. Class A Common Stock         GOOGL   \n",
       "4                    Amazon.com, Inc. Common Stock          AMZN   \n",
       "..                                             ...           ...   \n",
       "145            CVS Health Corporation Common Stock           CVS   \n",
       "146  Marsh & McLennan Companies, Inc. Common Stock           MMC   \n",
       "147   Automatic Data Processing, Inc. Common Stock           ADP   \n",
       "148                   Citigroup, Inc. Common Stock             C   \n",
       "149     Progressive Corporation (The) Common Stock           PGR   \n",
       "\n",
       "            market_cap                                                url  \n",
       "0    3,028,976,215,760  https://www.nasdaq.com/market-activity/stocks/...  \n",
       "1    2,769,810,931,198  https://www.nasdaq.com/market-activity/stocks/...  \n",
       "2    1,725,330,600,000  https://www.nasdaq.com/market-activity/stocks/...  \n",
       "3    1,705,242,420,000  https://www.nasdaq.com/market-activity/stocks/...  \n",
       "4    1,516,576,859,067  https://www.nasdaq.com/market-activity/stocks/...  \n",
       "..                 ...                                                ...  \n",
       "145     96,041,091,915  https://www.nasdaq.com/market-activity/stocks/cvs  \n",
       "146     96,033,253,582  https://www.nasdaq.com/market-activity/stocks/mmc  \n",
       "147     95,015,517,690  https://www.nasdaq.com/market-activity/stocks/adp  \n",
       "148     93,956,674,631    https://www.nasdaq.com/market-activity/stocks/c  \n",
       "149     93,577,293,075  https://www.nasdaq.com/market-activity/stocks/pgr  \n",
       "\n",
       "[150 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save stock list to data dir\n",
    "df.to_csv('../data/nasdaq_stock_list.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker_symbol</th>\n",
       "      <th>total_revenue</th>\n",
       "      <th>gross_profit</th>\n",
       "      <th>net_income</th>\n",
       "      <th>total_assets</th>\n",
       "      <th>total_liabilities</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ticker_symbol, total_revenue, gross_profit, net_income, total_assets, total_liabilities, year]\n",
       "Index: []"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "financials_df = pd.DataFrame(columns=['ticker_symbol', 'total_revenue', 'gross_profit', 'net_income', 'total_assets', 'total_liabilities', 'year'])\n",
    "# Init dataframe with the columns I want that are located in the financials table\n",
    "financials_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_financials(ticker, table, financials_to_scrape):\n",
    "    '''\n",
    "    Function to parse and extract financial data from a table\n",
    "    -----\n",
    "    Input:\n",
    "        ticker: str - ticker symbol\n",
    "        table: selenium table element\n",
    "        financials_to_scrape: list - list of strings of financials to scrape (e.g. ['Total Revenue', 'Gross Profit'])\n",
    "    -----\n",
    "    Returns:\n",
    "        df: A pandas dataframe containing the extracted data from that table corresponding to financials_to_scrape\n",
    "    '''\n",
    "    # Get table rows\n",
    "    try:\n",
    "        rows = table.find_elements(by=By.TAG_NAME, value=\"tr\")\n",
    "    except:\n",
    "        print(\"Error: No rows found\")\n",
    "        return None\n",
    "    \n",
    "    # Extract years from the table header\n",
    "    years = []\n",
    "    # Excluding the first column as its just the display name for recorded periods\n",
    "    for row in rows[0].find_elements(by=By.TAG_NAME, value=\"th\")[1:]:\n",
    "        years.append({'ticker_symbol': ticker, 'year': row.text[-4:]})\n",
    "\n",
    "    # Extract financial data from the table (First row is the header so we skip it)\n",
    "    for row in rows[1:]:\n",
    "        try:\n",
    "            # Extract columns from each row\n",
    "            cells = row.find_elements(by=By.CLASS_NAME, value=\"financials__cell\")\n",
    "            # Check if the row contains the data we want (financials_to_scrape)\n",
    "            if cells[0].text in financials_to_scrape:\n",
    "                for i, cell in enumerate(cells[1:]):\n",
    "                    years[i][cells[0].text.lower().replace(' ', '_')] = cell.text\n",
    "        except TimeoutException:\n",
    "            print(\"Error: Couldnt extract data from row\")\n",
    "            continue\n",
    "\n",
    "    return pd.DataFrame.from_dict(years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_financials_deprec(ticker, incomeStatementTable, balanceSheetTable):\n",
    "    '''\n",
    "    Deprecated function to parse and extract financial data from a table\n",
    "    Deprecated because I needed to scrape the data seperately as the tables technically loaded simultaneously, but only visible data could be scraped by selenium\n",
    "    '''\n",
    "    try:\n",
    "        is_rows = incomeStatementTable.find_elements(by=By.TAG_NAME, value=\"tr\")\n",
    "        bs_rows = balanceSheetTable.find_elements(by=By.TAG_NAME, value=\"tr\")\n",
    "    except:\n",
    "        print(\"Error: No rows found\")\n",
    "        return None\n",
    "    \n",
    "    years = []\n",
    "    for row in is_rows[0].find_elements(by=By.TAG_NAME, value=\"th\")[1:]:\n",
    "        years.append({'ticker_symbol': ticker, 'year': row.text[-4:]})\n",
    "\n",
    "    for row in is_rows[1:]:\n",
    "        try:\n",
    "            cells = row.find_elements(by=By.CLASS_NAME, value=\"financials__cell\")\n",
    "            # print(cells[0].text)\n",
    "            if cells[0].text in ['Net Income', 'Total Revenue', 'Gross Profit']:\n",
    "                # print(cells)\n",
    "                for i, cell in enumerate(cells[1:]):\n",
    "                    years[i][cells[0].text.lower().replace(' ', '_')] = cell.text\n",
    "        except TimeoutException:\n",
    "            print(\"Error: Couldnt extract data from row\")\n",
    "            continue\n",
    "\n",
    "    for row in bs_rows[1:]:\n",
    "        try:\n",
    "            cells = row.find_elements(by=By.CLASS_NAME, value=\"financials__cell\")\n",
    "            print(cells[0].text, cells[1].text, cells[2].text, cells[3].text, cells[4].text)\n",
    "            if cells[0].text in ['Total Assets', 'Total Liabilities']:\n",
    "                for i, cell in enumerate(cells[1:]):\n",
    "                    years[i][cells[0].text.lower().replace(' ', '_')] = cell.text\n",
    "        except TimeoutException:\n",
    "            print(\"Error: Couldnt extract data from row\")\n",
    "            continue\n",
    "\n",
    "    return pd.DataFrame.from_dict(years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find data tables on https://www.nasdaq.com/market-activity/stocks/brk/a/financials\n",
      "Could not find data tables on https://www.nasdaq.com/market-activity/stocks/brk/b/financials\n",
      "Could not find data tables on https://www.nasdaq.com/market-activity/stocks/brk/a/financials\n",
      "Could not find data tables on https://www.nasdaq.com/market-activity/stocks/brk/b/financials\n",
      "Could not find data tables on https://www.nasdaq.com/market-activity/stocks/nee/financials\n"
     ]
    }
   ],
   "source": [
    "# Extracing the financial data for each ticker\n",
    "for ticker, url in zip(df['ticker_symbol'], df['url']):\n",
    "    try:\n",
    "        driver.get(url + '/financials')\n",
    "    except:\n",
    "        raise Exception(f'Could not load {url + \"/financials\"}')\n",
    "    \n",
    "    # Wait until the data table we want is visible on the page:\n",
    "    try:\n",
    "        wait.until(EC.visibility_of_element_located((By.CLASS_NAME, 'financials__body')))\n",
    "\n",
    "        # Extract the income statement and scrape the data\n",
    "        is_table = driver.find_element(by=By.XPATH, value='//div[@data-panel-name=\"incomeStatementTable\"]')\n",
    "        is_data_list = scrape_financials(ticker, is_table, ['Total Revenue', 'Gross Profit', 'Net Income']) # this can be modified to scrape more or less data from the table\n",
    "                                                                                                            # just insure the strings match the table data\n",
    "        # Click onto balance sheet tab and scrape the data\n",
    "        bs_button = driver.find_element(by=By.XPATH, value='//button[@data-value=\"balanceSheetTable\"]')\n",
    "        bs_button.click()\n",
    "\n",
    "        bs_table = driver.find_element(by=By.XPATH, value='//div[@data-panel-name=\"balanceSheetTable\"]')\n",
    "        bs_data_list = scrape_financials(ticker, bs_table, ['Total Assets', 'Total Liabilities'])\n",
    "\n",
    "        # Merge the two dataframes\n",
    "        data_list = pd.merge(is_data_list, bs_data_list, on=['ticker_symbol', 'year'])\n",
    "        financials_df = pd.concat([financials_df, data_list], ignore_index=True)\n",
    "    except TimeoutException:\n",
    "        # Appending an empty dict with the ticker and year to the dataframe to indicate that no data was found\n",
    "        no_data_dict = {'ticker_symbol': ticker, 'year': 'No data found'}\n",
    "        temp_df = pd.DataFrame.from_dict([no_data_dict])\n",
    "        financials_df = pd.concat([financials_df, temp_df], ignore_index=True)\n",
    "        print(f'Could not find data tables on {url + \"/financials\"}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker_symbol</th>\n",
       "      <th>total_revenue</th>\n",
       "      <th>gross_profit</th>\n",
       "      <th>net_income</th>\n",
       "      <th>total_assets</th>\n",
       "      <th>total_liabilities</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>$383,285,000</td>\n",
       "      <td>$169,148,000</td>\n",
       "      <td>$96,995,000</td>\n",
       "      <td>$352,583,000</td>\n",
       "      <td>$290,437,000</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>$394,328,000</td>\n",
       "      <td>$170,782,000</td>\n",
       "      <td>$99,803,000</td>\n",
       "      <td>$352,755,000</td>\n",
       "      <td>$302,083,000</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>$365,817,000</td>\n",
       "      <td>$152,836,000</td>\n",
       "      <td>$94,680,000</td>\n",
       "      <td>$351,002,000</td>\n",
       "      <td>$287,912,000</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>$274,515,000</td>\n",
       "      <td>$104,956,000</td>\n",
       "      <td>$57,411,000</td>\n",
       "      <td>$323,888,000</td>\n",
       "      <td>$258,549,000</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>$211,915,000</td>\n",
       "      <td>$146,052,000</td>\n",
       "      <td>$72,361,000</td>\n",
       "      <td>$411,976,000</td>\n",
       "      <td>$205,753,000</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>C</td>\n",
       "      <td>$65,242,000</td>\n",
       "      <td>$65,242,000</td>\n",
       "      <td>$19,401,000</td>\n",
       "      <td>$1,951,158,000</td>\n",
       "      <td>$1,757,916,000</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>PGR</td>\n",
       "      <td>$49,610,700</td>\n",
       "      <td>$1,711,400</td>\n",
       "      <td>$721,500</td>\n",
       "      <td>$75,465,000</td>\n",
       "      <td>$59,574,000</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>PGR</td>\n",
       "      <td>$47,702,000</td>\n",
       "      <td>$4,706,900</td>\n",
       "      <td>$3,350,900</td>\n",
       "      <td>$71,132,300</td>\n",
       "      <td>$52,900,700</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>PGR</td>\n",
       "      <td>$42,658,100</td>\n",
       "      <td>$7,615,700</td>\n",
       "      <td>$5,704,600</td>\n",
       "      <td>$64,098,300</td>\n",
       "      <td>$47,059,700</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>PGR</td>\n",
       "      <td>$39,022,300</td>\n",
       "      <td>$5,553,500</td>\n",
       "      <td>$3,970,300</td>\n",
       "      <td>$54,910,500</td>\n",
       "      <td>$41,011,700</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>587 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ticker_symbol total_revenue  gross_profit   net_income    total_assets  \\\n",
       "0            AAPL  $383,285,000  $169,148,000  $96,995,000    $352,583,000   \n",
       "1            AAPL  $394,328,000  $170,782,000  $99,803,000    $352,755,000   \n",
       "2            AAPL  $365,817,000  $152,836,000  $94,680,000    $351,002,000   \n",
       "3            AAPL  $274,515,000  $104,956,000  $57,411,000    $323,888,000   \n",
       "4            MSFT  $211,915,000  $146,052,000  $72,361,000    $411,976,000   \n",
       "..            ...           ...           ...          ...             ...   \n",
       "582             C   $65,242,000   $65,242,000  $19,401,000  $1,951,158,000   \n",
       "583           PGR   $49,610,700    $1,711,400     $721,500     $75,465,000   \n",
       "584           PGR   $47,702,000    $4,706,900   $3,350,900     $71,132,300   \n",
       "585           PGR   $42,658,100    $7,615,700   $5,704,600     $64,098,300   \n",
       "586           PGR   $39,022,300    $5,553,500   $3,970,300     $54,910,500   \n",
       "\n",
       "    total_liabilities  year  \n",
       "0        $290,437,000  2023  \n",
       "1        $302,083,000  2022  \n",
       "2        $287,912,000  2021  \n",
       "3        $258,549,000  2020  \n",
       "4        $205,753,000  2023  \n",
       "..                ...   ...  \n",
       "582    $1,757,916,000  2019  \n",
       "583       $59,574,000  2022  \n",
       "584       $52,900,700  2021  \n",
       "585       $47,059,700  2020  \n",
       "586       $41,011,700  2019  \n",
       "\n",
       "[587 rows x 7 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "financials_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "financials_df.to_csv('../data/nasdaq_listed_company_financials.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
